{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key='8fa5447458264d2daca1d2bc7e48e790'\n",
    "endpoint='https://sunil-cv.cognitiveservices.azure.com/'\n",
    "computervision_client=ComputerVisionClient(endpoint,CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discription_result=computervision_client.describe_image(remote_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Describe an image - remote*********\n",
      "Description of remote image: \n",
      "'an ancient city with many ruins with Colosseum in the background' with confidance 33.80%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Describe  an image - remote\n",
    "To describe the contents of remote image with a confidance score.\n",
    "'''\n",
    "\n",
    "print(\"******* Describe an image - remote*********\")\n",
    "# Call API\n",
    "discription_results=computervision_client.describe_image(remote_image_url)\n",
    "\n",
    "# Get the caption (discription) from the reponses, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(discription_results.captions)== 0):\n",
    "    print(\"No Discription detected.\")\n",
    "else:\n",
    "    for caption in discription_results.captions:\n",
    "        print(\"'{}' with confidance {:.2f}%\".format(caption.text, caption.confidence*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Categorize an image - remote*********\n",
      "Categories from remote image: \n",
      "'building_' with confidance 31.64%\n",
      "'others_' with confidance 0.39%\n",
      "'outdoor_' with confidance 3.91%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Categorize an image - remote\n",
    "To extract categories from a remote image with a confidance score.\n",
    "'''\n",
    "print(\"******* Categorize an image - remote*********\")\n",
    "# Select the visual feature(s)\n",
    "remote_image_features= [\"categories\"]\n",
    "#Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url,remote_image_features)\n",
    "\n",
    "#Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len (categorize_results_remote.categories)== 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "      print(\"'{}' with confidance {:.2f}%\".format(category.name, category.score*100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Tag an image*****\n",
      "Tag in remote image: \n",
      "'outdoor' with confidance 99.00%\n",
      "'building' with confidance 98.81%\n",
      "'sky' with confidance 98.21%\n",
      "'stadium' with confidance 98.17%\n",
      "'ancient rome' with confidance 96.16%\n",
      "'ruins' with confidance 95.04%\n",
      "'amphitheatre' with confidance 93.99%\n",
      "'ancient roman architecture' with confidance 92.65%\n",
      "'historic site' with confidance 89.55%\n",
      "'ancient history' with confidance 89.54%\n",
      "'history' with confidance 86.72%\n",
      "'archaeological site' with confidance 84.41%\n",
      "'travel' with confidance 65.85%\n",
      "'large' with confidance 61.02%\n",
      "'city' with confidance 56.57%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tag an image - remote\n",
    "Tag a key words for each thing in the image.\n",
    "'''\n",
    "print(\"**********Tag an image*****\")\n",
    "#call API with remote image\n",
    "tags_result_remote=computervision_client.tag_image(remote_image_url)\n",
    "\n",
    "#Print results with confidence score \n",
    "print(\"Tag in remote image: \")\n",
    "if (len (tags_result_remote.tags)== 0):\n",
    "    print(\"No tag detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "      print(\"'{}' with confidance {:.2f}%\".format(tag.name, tag.confidence*100)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Detect object -remote *****\n",
      "Detecting objects in remote image: \n",
      "No objects detected.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DetectObjects - remote\n",
    "Detect different kind of object in the image.\n",
    "'''\n",
    "print(\"**********Detect object -remote *****\")\n",
    "#Get URL image with different object\n",
    "\n",
    "remote_image_url_objects='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg'\n",
    "#Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects) \n",
    "\n",
    "#Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image: \")\n",
    "if len (detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object name {} with confidance {:.2f}% at location {},{},{},{}\".format(object.object_properties, object.confidence*100,\\\n",
    "        object.rectangle.x,object.rectangle.x + object.rectangle.w,\\\n",
    "        object.rectangle.y,object.rectangle.y + object.rectangle.h)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Detect Domain Specific Content -remote *****\n"
     ]
    },
    {
     "ename": "ComputerVisionErrorResponseException",
     "evalue": "(InvalidRequest) Feature is not supported. Please apply for access at https://aka.ms/celebrityrecognition",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mComputerVisionErrorResponseException\u001b[0m      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m remote_image_url_celeb\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39m#Call API with content type and URL\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m detect_domain_results_celebs_remote\u001b[39m=\u001b[39m computervision_client\u001b[39m.\u001b[39;49manalyze_image_by_domain(\u001b[39m\"\u001b[39;49m\u001b[39mcelebrities\u001b[39;49m\u001b[39m\"\u001b[39;49m, remote_image_url_celeb) \n\u001b[0;32m     13\u001b[0m \u001b[39m#Print detected results with name\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCelebrities names in remote image: \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\azure\\cognitiveservices\\vision\\computervision\\operations\\_computer_vision_client_operations.py:424\u001b[0m, in \u001b[0;36mComputerVisionClientOperationsMixin.analyze_image_by_domain\u001b[1;34m(self, model, url, language, model_version, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    421\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39msend(request, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moperation_config)\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n\u001b[1;32m--> 424\u001b[0m     \u001b[39mraise\u001b[39;00m models\u001b[39m.\u001b[39mComputerVisionErrorResponseException(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deserialize, response)\n\u001b[0;32m    426\u001b[0m deserialized \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
      "\u001b[1;31mComputerVisionErrorResponseException\u001b[0m: (InvalidRequest) Feature is not supported. Please apply for access at https://aka.ms/celebrityrecognition"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Domain Specific Content - remote\n",
    "Detects celebrites and landmark in remote images\n",
    ".\n",
    "'''\n",
    "print(\"**********Detect Domain Specific Content -remote *****\")\n",
    "#Get URL of one or more celebrities\n",
    "remote_image_url_celeb='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg'\n",
    "#Call API with content type and URL\n",
    "\n",
    "detect_domain_results_celebs_remote= computervision_client.analyze_image_by_domain(\"celebrities\", remote_image_url_celeb) \n",
    "\n",
    "#Print detected results with name\n",
    "print(\"Celebrities names in remote image: \")\n",
    "if len(detect_domain_results_celebs_remote.result[\"celebrities\"]) == 0:\n",
    "    print(\"No celebrities detected.\")\n",
    "else:\n",
    "    for celeb in detect_domain_results_celebs_remote.result[\"celebrities\"]:\n",
    "        print(celeb[\"name\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Detect Brand Content -remote *****\n",
      "Detecting brands in remote image: \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m#Print detected objects results with bounding boxes\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDetecting brands in remote image: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(detect_brands_results_remote\u001b[39m.\u001b[39;49mbrands) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo brands detected.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Brands - remote\n",
    "Detect common brands like logos and put a bounding box around them.\n",
    "'''\n",
    "print(\"**********Detect Brand Content -remote *****\")\n",
    "#Get URL image with brand logo\n",
    "remote_image_url='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg'\n",
    "#Select the visuals features \n",
    "remote_image_feature = [\"brands\"]\n",
    "\n",
    "#Call API with URL and features\n",
    "\n",
    "detect_brands_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features) \n",
    "\n",
    "#Print detected objects results with bounding boxes\n",
    "print(\"Detecting brands in remote image: \")\n",
    "if len(detect_brands_results_remote.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in detect_brands_results_remote.brands:\n",
    "        print(\"'{}' brand detected with confidance {:.1f}% at location {},{},{},{}\".format(\\\n",
    "        brand.name, brand.confidence *100, brand.rectangle.x,brand.rectangle.x + brand.rectangle.w,\\\n",
    "        brand.rectangle.y,brand.rectangle.y + brand.rectangle.h)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Detect image type -remote *****\n",
      "Type of remote image:\n",
      "Image is not clip art.:\n",
      "Image is not a line drawing.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect image type - remote\n",
    "Detects image types\n",
    ".\n",
    "'''\n",
    "print(\"**********Detect image type -remote *****\")\n",
    "#Get URL of an image with a type\n",
    "remote_image_url_type='https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg'\n",
    "#Select visual features\n",
    "remote_image_features=[VisualFeatureTypes.image_type]\n",
    "#Call API with URL and Features\n",
    "detect_type_results_remote= computervision_client.analyze_image( remote_image_url_type, remote_image_features) \n",
    "\n",
    "#Print type result with degree of accuracy\n",
    "print(\"Type of remote image:\")\n",
    "if detect_type_results_remote.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not clip art.:\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 1:\n",
    "    print(\"Image is ambiguously clip art.:\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 2:\n",
    "    print(\"Image is normal clip art.:\")\n",
    "else:\n",
    "    print (\"Image is good clip art\")\n",
    "    \n",
    "if detect_type_results_remote.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not a line drawing.\")\n",
    "else:\n",
    "    print(\"Image is a line drawing.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
